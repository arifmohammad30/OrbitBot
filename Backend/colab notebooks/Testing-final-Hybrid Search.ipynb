{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALLATIONS & SETUP\n",
        "# ==============================================================================\n",
        "!pip install langchain langchain-community neo4j chromadb sentence-transformers langchain-together -q\n",
        "!pip install python-dotenv nest_asyncio -q\n"
      ],
      "metadata": {
        "id": "15cdXTLIYYsZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Hybrid Search\n",
        "\n",
        "# --- Step 1: Install and Import Libraries ---\n",
        "print(\"--- Step 1: Installing and Importing Libraries ---\")\n",
        "# Use os.system for pip installs for robustness in Colab environments\n",
        "os.system(\"pip install langchain langchain-community neo4j chromadb sentence-transformers langchain-together -q --progress-bar off\")\n",
        "os.system(\"pip install python-dotenv nest_asyncio -q --progress-bar off\")\n",
        "\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from typing import List\n",
        "\n",
        "# LangChain core components\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.graphs import Neo4jGraph # For KG connection\n",
        "from langchain_together import ChatTogether # For Together AI LLM\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings # For embeddings\n",
        "# No more explicit PydanticOutputParser/RetryOutputParser as final output is text\n",
        "from langchain.prompts import PromptTemplate # For managing prompts\n",
        "from langchain.chains import RetrievalQA # For the RAG chain\n",
        "\n",
        "# Removed Pydantic BaseModel/Field as they are not used for final output anymore\n",
        "# from pydantic import BaseModel, Field # Not needed for final_answer\n",
        "\n",
        "print(\"‚úÖ Installations and Imports Complete.\")\n",
        "\n",
        "# --- Step 2: Configure Paths, Keys, Connections ---\n",
        "print(\"\\n--- Step 2: Configuring Connections ---\")\n",
        "TOGETHER_API_KEY = \"tgp_v1_EJqfkWuqVVQVbYIVhvXU_7_JoKGomJqL7HhfHVyQm_E\"\n",
        "NEO4J_URI = \"neo4j+s://9dae82f0.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"DUHXAf9g5PK25qfmJ63RbEbaw9tYyWeSu9MJjPwAnic\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "print(\"\\nCopying ChromaDB from Google Drive to local Colab...\")\n",
        "DRIVE_DB_PATH = \"/content/drive/MyDrive/chroma_db\"\n",
        "LOCAL_DB_PATH = \"/content/local_chroma_db\"\n",
        "\n",
        "os.makedirs(os.path.dirname(LOCAL_DB_PATH), exist_ok=True)\n",
        "if os.path.exists(DRIVE_DB_PATH):\n",
        "    if os.path.exists(LOCAL_DB_PATH):\n",
        "        shutil.rmtree(LOCAL_DB_PATH)\n",
        "    try:\n",
        "        shutil.copytree(DRIVE_DB_PATH, LOCAL_DB_PATH)\n",
        "        print(\"‚úÖ ChromaDB copy complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error copying ChromaDB from Drive: {e}\")\n",
        "        print(\"Proceeding without local copy. Expect potential I/O errors if DB is large.\")\n",
        "else:\n",
        "    print(\"‚ùå ChromaDB not found on Drive. Please check path. Attempting to proceed with empty local dir.\")\n",
        "    os.makedirs(LOCAL_DB_PATH, exist_ok=True) # Ensure dir exists even if empty\n",
        "\n",
        "CHROMA_PERSIST_DIR = LOCAL_DB_PATH\n",
        "CHROMA_COLLECTION_NAME = \"mosdac_knowledge_unified\"\n",
        "\n",
        "print(\"‚úÖ Environment and Paths Configured.\")\n",
        "\n",
        "# --- Step 3: Initialize LLM, KG, VectorDB ---\n",
        "print(\"\\n--- Step 3: Initializing Models ---\")\n",
        "\n",
        "llm = ChatTogether(\n",
        "    together_api_key=TOGETHER_API_KEY,\n",
        "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=2048\n",
        ")\n",
        "print(\"‚úÖ LLM Initialized.\")\n",
        "\n",
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "print(\"‚úÖ Embedding Model Loaded.\")\n",
        "\n",
        "try:\n",
        "    graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)\n",
        "    # CORRECTED: Removed graph.run(\"RETURN 1\") - Neo4jGraph from LangChain does not have this method.\n",
        "    print(\"‚úÖ Connected to Neo4j KG.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to connect to Neo4j: {e}\")\n",
        "    # Do NOT raise here, as KG is accepted to be imperfect for submission.\n",
        "\n",
        "try:\n",
        "    vector_store = Chroma(\n",
        "        collection_name=CHROMA_COLLECTION_NAME,\n",
        "        persist_directory=CHROMA_PERSIST_DIR,\n",
        "        embedding_function=embedding_model\n",
        "    )\n",
        "    retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
        "    print(f\"‚úÖ Vector DB Loaded: {vector_store._collection.count()} documents.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load ChromaDB: {e}\")\n",
        "    # Do NOT raise here, as VectorDB is accepted to be imperfect for submission.\n",
        "\n",
        "# --- Step 4: Define KG and RAG Query Functions ---\n",
        "print(\"\\n--- Step 4: Defining Query Functions ---\")\n",
        "\n",
        "# Known clean entity names in your KG (based on your KG creation script's output sample)\n",
        "# Populate this list with actual clean names you expect to hit.\n",
        "key_kg_entities = [\n",
        "    \"MOSDAC\", \"Kalpana-1\", \"INSAT-3D\", \"INSAT-3DR\", \"Oceansat-2\", \"SARAL-AltiKa\",\n",
        "    \"OCM\", \"LISS-IV\", \"ISRO\", \"NRSC\", \"Space Applications Centre\"\n",
        "]\n",
        "\n",
        "async def query_knowledge_graph_async(question: str):\n",
        "    print(\"üß† Querying Knowledge Graph...\")\n",
        "    # Handle case where graph connection failed at initialization\n",
        "    if 'graph' not in globals() or graph is None:\n",
        "        return \"KG is not connected.\"\n",
        "\n",
        "    found_entities = []\n",
        "    for entity in key_kg_entities:\n",
        "        if re.search(r'\\b' + re.escape(entity) + r'\\b', question, re.IGNORECASE):\n",
        "            found_entities.append(entity)\n",
        "\n",
        "    if not found_entities:\n",
        "        return \"KG: No relevant entities found for this query.\"\n",
        "\n",
        "    results = []\n",
        "    for entity in found_entities:\n",
        "        cypher = f\"\"\"\n",
        "        MATCH (n)\n",
        "        WHERE toLower(n.name) = toLower('{entity}') OR toLower(n.description) CONTAINS toLower('{entity}')\n",
        "        RETURN n.name AS name, n.description AS description, labels(n) AS labels\n",
        "        LIMIT 1\n",
        "        \"\"\"\n",
        "        try:\n",
        "            query_result = await asyncio.to_thread(graph.query, cypher)\n",
        "            if query_result:\n",
        "                for record in query_result:\n",
        "                    results.append(\n",
        "                        f\"KG Fact: Name='{record.get('name')}', Description='{record.get('description')}'\"\n",
        "                    )\n",
        "            else:\n",
        "                results.append(f\"KG: No direct fact found for '{entity}'.\")\n",
        "        except Exception as e:\n",
        "            # Provide a clean error message, not a full traceback to LLM\n",
        "            results.append(f\"KG Error for '{entity}': Query execution failed.\")\n",
        "    return \"\\n\".join(results)\n",
        "\n",
        "async def query_vector_db_async(question: str):\n",
        "    print(\"üìö Querying Vector DB...\")\n",
        "    # Handle case where vector_store connection failed at initialization\n",
        "    if 'vector_store' not in globals() or vector_store is None:\n",
        "        return \"VectorDB is not loaded.\"\n",
        "\n",
        "    try:\n",
        "        docs = await asyncio.to_thread(retriever.get_relevant_documents, question)\n",
        "        return \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No documents found.\"\n",
        "    except Exception as e:\n",
        "        # Provide a clean error message, not a full traceback to LLM\n",
        "        return f\"VectorDB Error: Data retrieval failed.\"\n",
        "\n",
        "# --- Step 5: Main Hybrid Search Function ---\n",
        "print(\"\\n--- Step 5: Defining Test Function ---\")\n",
        "\n",
        "async def test_hybrid_search(user_question: str):\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"‚ùì TESTING QUESTION: {user_question}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    kg_task = query_knowledge_graph_async(user_question)\n",
        "    rag_task = query_vector_db_async(user_question)\n",
        "    kg_results, rag_results = await asyncio.gather(kg_task, rag_task)\n",
        "\n",
        "    print(\"\\n--- INTERMEDIATE RESULTS ---\")\n",
        "    print(f\"üß† KG Context:\\n{kg_results}\")\n",
        "    print(f\"\\nüìö Vector DB Context:\\n{rag_results}\")\n",
        "    print(\"----------------------------\\n\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert assistant for ISRO's MOSDAC portal.\n",
        "\n",
        "Use the following information to answer the user's question clearly and concisely.\n",
        "\n",
        "--- KG FACTS ---\n",
        "{kg_results}\n",
        "\n",
        "--- DOCUMENTS ---\n",
        "{rag_results}\n",
        "\n",
        "If the 'KG FACTS' section contains 'KG Error' or 'No relevant entities found', disregard it and answer solely using 'DOCUMENTS'.\n",
        "If both 'KG FACTS' and 'DOCUMENTS' are weak or indicate no results, provide a helpful fallback answer based on general knowledge about MOSDAC, clarifying that specific information wasn't found.\n",
        "Ensure your answer directly addresses the USER QUESTION and avoids making up information.\n",
        "\n",
        "USER QUESTION: {user_question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "    try:\n",
        "        # Direct LLM invocation, no JSON parsing\n",
        "        response = await llm.ainvoke(prompt)\n",
        "        print(\"\\n‚úÖ FINAL OUTPUT:\")\n",
        "        print(response.content) # Print the content of the AI message\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Failed to generate final answer: {e}\")\n",
        "\n",
        "# --- Step 6: Run Demo Questions ---\n",
        "print(\"\\n--- Step 6: Executing Tests ---\")\n",
        "nest_asyncio.apply()\n",
        "\n",
        "test_questions = [\n",
        "    \"What is Kalpana-1?\",\n",
        "    \"what are payloads of kalpana -1.\"\n",
        "]\n",
        "\n",
        "async def run_all_tests():\n",
        "    for q in test_questions:\n",
        "        await test_hybrid_search(q)\n",
        "\n",
        "# RUN TESTS\n",
        "await run_all_tests()\n",
        "print(\"\\n‚úÖ All tests completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ySqsk7w9Sd",
        "outputId": "0e6bdfb3-4aa1-4e15-df6f-e17da358a3ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Installing and Importing Libraries ---\n",
            "‚úÖ Installations and Imports Complete.\n",
            "\n",
            "--- Step 2: Configuring Connections ---\n",
            "Mounted at /content/drive\n",
            "\n",
            "Copying ChromaDB from Google Drive to local Colab...\n",
            "‚úÖ ChromaDB copy complete.\n",
            "‚úÖ Environment and Paths Configured.\n",
            "\n",
            "--- Step 3: Initializing Models ---\n",
            "‚úÖ LLM Initialized.\n",
            "‚úÖ Embedding Model Loaded.\n",
            "‚úÖ Connected to Neo4j KG.\n",
            "‚úÖ Vector DB Loaded: 61606 documents.\n",
            "\n",
            "--- Step 4: Defining Query Functions ---\n",
            "\n",
            "--- Step 5: Defining Test Function ---\n",
            "\n",
            "--- Step 6: Executing Tests ---\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: What is Kalpana-1?\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG: No direct fact found for 'Kalpana-1'.\n",
            "\n",
            "üìö Vector DB Context:\n",
            "Link Text KALPANA 1 Winds Target URL Context ...node 464 130 Wed 2017-01-04 09 46 alt text KALPANA 1 Winds Wed 2017-04-12 10 57 alt text INSAT-3D Sounder Cloud Mask https ...\n",
            "Link Text KALPANA-1 Target URL Context ... INSAT-3DR INSAT-3D KALPANA-1 INSAT-3A MeghaTropiques ...\n",
            "Link Text KALPANA-1 Target URL Context ... INSAT-3DR INSAT-3D KALPANA-1 INSAT-3A MeghaTropiques ...\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " Kalpana-1 is a weather satellite. It is one of the satellites mentioned in the documents you provided, along with INSAT-3DR, INSAT-3D, INSAT-3A, and MeghaTropiques. These satellites are part of the Indian National Satellite System (INSAT) operated by the Indian Space Research Organisation (ISRO). The Kalpana-1 satellite, also known as MetSat-1, was launched in 2002 and provided weather-related data for various applications, including meteorological analysis, weather forecasting, and disaster management.\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: What are satellites present in mosdac portal?\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG Fact: Name='mosdac', Description=''\n",
            "\n",
            "üìö Vector DB Context:\n",
            "of selected satellite.Select Catalog -- In-situ -- distribution from top menu bar. All In-situ list will be displayed for which MOSDAC has datasets. Select Catalog -- In-situ -- distribution from top menu bar. All In-situ list will be displayed for which MOSDAC has datasets.\n",
            "Question What datasets are available on MOSDAC Answer Select Catalog -- Satellite data from top menu bar. All data products list of a satellite will be displayed. You can change the satellite to view data products of selected satellite. Select Catalog -- Satellite data from top menu bar. All data products list of a satellite will be displayed. You can change the satellite to view data products of selected satellite.Select Catalog -- In-situ -- distribution from top menu bar. All In-situ list\n",
            "Question What is MOSDAC Answer MOSDAC is the short form of Meteorological and Oceanographic Satellite Data Archival Center. It is a ISRO data portal which provides data through its web based service\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " To find out the satellites present in the MOSDAC (Meteorological and Oceanographic Satellite Data Archival Center) portal, you can follow these steps:\n",
            "\n",
            "1. Visit the MOSDAC portal.\n",
            "2. Select \"Catalog\" from the top menu bar.\n",
            "3. Choose \"Satellite data\" from the dropdown menu.\n",
            "\n",
            "By doing so, you will be able to view the list of all data products associated with different satellites. The available satellites are listed within these data products. However, the specific user interface and options might vary, so it's always a good idea to explore the portal and familiarize yourself with its features.\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: What are the applications of SARAL-AltiKa data?\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG Fact: Name='SARAL-AltiKa', Description=''\n",
            "\n",
            "üìö Vector DB Context:\n",
            "Link Text SARAL-AltiKa Target URL Context ...Help You are here Home Missions SARAL-AltiKa Documents SARAL References SARAL Products Handbook\n",
            "Link Text Missions Target URL Context ...s Sitemap Help You are here Home Missions SARAL-AltiKa SARAL-AltiKa SARAL mission results from the common interest of both CNES and ISRO in studying ocean from space using altimetry syste...\n",
            "Link Text SARAL-AltiKa Target URL Context ...mosdac.gov.in kalpana-1 INSAT-3A MeghaTropiques SARAL-AltiKa OCEANSAT-2 OCEANSAT-3 INSAT-3DS\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " The SARAL-AltiKa mission is a result of the common interest of both CNES and ISRO in studying the ocean from space using altimetry systems. Although the specific applications of SARAL-AltiKa data are not mentioned in the provided KG Facts, I can look into the documents section to provide more information.\n",
            "\n",
            "According to the MOSDAC documents, SARAL-AltiKa is one of the missions listed under ISRO's satellite missions. However, the applications of SARAL-AltiKa data are not directly provided in the given document links. Typically, altimetry satellite data like SARAL-AltiKa are used for various applications, including monitoring ocean surface topography, studying ocean currents, and contributing to weather and climate predictions.\n",
            "\n",
            "For detailed and specific information regarding SARAL-AltiKa data applications, I would recommend visiting the MOSDAC portal's SARAL-AltiKa Documents section and looking for the mission's product handbook or related references, as they might contain the desired information.\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: What is MOSDAC?\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG Fact: Name='mosdac', Description=''\n",
            "\n",
            "üìö Vector DB Context:\n",
            "Question What is MOSDAC Answer MOSDAC is the short form of Meteorological and Oceanographic Satellite Data Archival Center. It is a ISRO data portal which provides data through its web based service\n",
            "Home English Hindi English - - MOSDAC Single-Sign-On SSO Username or email Password Forgot Password Owned and maintained by MOSDAC Space Applications Centre Indian Space Research Organisation Govt. of INDIA.\n",
            "Home English Hindi English - - MOSDAC Single-Sign-On SSO Username or email Password Forgot Password Owned and maintained by MOSDAC Space Applications Centre Indian Space Research Organisation Govt. of INDIA.\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " MOSDAC stands for Meteorological and Oceanographic Satellite Data Archival Center. It is a data portal owned and maintained by the Space Applications Centre under the Indian Space Research Organisation, part of the Indian government. MOSDAC provides data through its web-based service.\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: Tell me about Oceansat-2 OCM data.\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG: No direct fact found for 'Oceansat-2'.\n",
            "KG Fact: Name='OCM', Description=''\n",
            "\n",
            "üìö Vector DB Context:\n",
            "Link Text OCEANSAT-3 Target URL Context ... You are here Home Missions OCEANSAT-3 Documents OCEANSAT-3 References OCM AOD ATBD V1 1.pd...\n",
            "Link Text OCEANSAT-3 Target URL Context ... You are here Home Missions OCEANSAT-3 Objectives OCEANSAT-3 Objectives To ensure the data continuity of Ocean colour and wind vector data to sustain the operational applications....\n",
            "Link Text OCEANSAT-2 Target URL Context ... You are here Home Missions OCEANSAT-2 Objectives Oceansat-2 Objectives The Indian satellite Oceansat-2 is designed to provide service continuity for operational users of the Ocean Col...\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " The Ocean Colour Monitor (OCM) is a instrument onboard the Oceansat-2 satellite. However, I couldn't find specific documents or facts related to the Oceansat-2 OCM data in the provided knowledge graph and documents. Therefore, I'm unable to provide detailed information about the Oceansat-2 OCM data. I recommend visiting the MOSDAC portal and looking for resources or contacts who can provide specific assistance regarding Oceansat-2 OCM data.\n",
            "================================================================================\n",
            "‚ùì TESTING QUESTION: Explain the different processing levels for satellite data.\n",
            "================================================================================\n",
            "üß† Querying Knowledge Graph...\n",
            "üìö Querying Vector DB...\n",
            "\n",
            "--- INTERMEDIATE RESULTS ---\n",
            "üß† KG Context:\n",
            "KG: No relevant entities found for this query.\n",
            "\n",
            "üìö Vector DB Context:\n",
            "the earth s surface oceanic observations and also provide data dissemination capabilities. It provides Broadcast Satellite Services BSS through two S-band transponders. The data acquisition and processing system is established at Space Applications Centre Bopal Campus Ahmedabad India. The processing of INSAT-3D data is taken place broadly in four steps. 1. Ground receiving system to receive data 2. Data Reception DR system to generate raw data L0 files 3. Data Processing DP system to process L0\n",
            "the earth s surface oceanic observations and also provide data dissemination capabilities. It provides Broadcast Satellite Services BSS through two S-band transponders. The data acquisition and processing system is established at Space Applications Centre Bopal Campus Ahmedabad India. The processing of INSAT-3D data is taken place broadly in four steps. 1. Ground receiving system to receive data 2. Data Reception DR system to generate raw data L0 files 3. Data Processing DP system to process L0\n",
            "the earth s surface oceanic observations and also provide data dissemination capabilities. It provides Broadcast Satellite Services BSS through two S-band transponders. The data acquisition and processing system is established at Space Applications Centre Bopal Campus Ahmedabad India. The processing of INSAT-3D data is taken place broadly in four steps. 1. Ground receiving system to receive data 2. Data Reception DR system to generate raw data L0 files 3. Data Processing DP system to process L0\n",
            "----------------------------\n",
            "\n",
            "\n",
            "‚úÖ FINAL OUTPUT:\n",
            " The processing of satellite data, specifically INSAT-3D data, occurs in four main steps. First, the Ground Receiving System receives the data. Next, the Data Reception (DR) system generates raw data L0 files. Then, the Data Processing (DP) system processes the L0 files into higher level products, which can include L1 (calibrated and geolocated data), L2 (derived data products), and L3 (further processed data products). Lastly, the data is disseminated for various applications and uses.\n",
            "\n",
            "‚úÖ All tests completed.\n"
          ]
        }
      ]
    }
  ]
}